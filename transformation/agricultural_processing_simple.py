#!/usr/bin/env python3
"""
Transformations simplifi√©es pour les donn√©es agricoles
Version utilisant pandas pour plus de simplicit√©
"""
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import numpy as np

print("=" * 70)
print("üåæ TRANSFORMATIONS - DONN√âES AGRICOLES")
print("=" * 70)
print(f"‚è∞ Heure de d√©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()

# Chemins
RAW_PATH = Path("data_lake/raw/agriculture")
PROCESSED_PATH = Path("data_lake/processed/agriculture")
PROCESSED_PATH.mkdir(parents=True, exist_ok=True)

# ============================================================================
# 1. AGR√âGATION DES CAPTEURS IOT
# ============================================================================
print("üìä TRANSFORMATION 1: Agr√©gation des capteurs IoT")
print("-" * 70)

# Charger les donn√©es capteurs
with open(RAW_PATH / "sensors.json", 'r') as f:
    sensors_data = json.load(f)

sensors_df = pd.DataFrame(sensors_data)
print(f"   ‚úÖ Charg√© {len(sensors_df)} lectures de capteurs")

# Convertir timestamp en date
sensors_df['timestamp'] = pd.to_datetime(sensors_df['timestamp'])
sensors_df['reading_date'] = sensors_df['timestamp'].dt.date

# Agr√©gation par parcelle, date et type de capteur
sensors_agg = sensors_df.groupby(['field_id', 'reading_date', 'sensor_type']).agg({
    'value': ['count', 'mean', 'min', 'max', 'std'],
    'unit': 'first'
}).reset_index()

# Aplatir les colonnes multi-niveaux
sensors_agg.columns = ['field_id', 'reading_date', 'sensor_type', 
                        'num_readings', 'avg_value', 'min_value', 'max_value', 'stddev_value', 'unit']

# Sauvegarder
output_file = PROCESSED_PATH / "sensors_aggregated.json"
sensors_agg.to_json(output_file, orient='records', date_format='iso', indent=2)
print(f"   ‚úÖ Sauvegard√© {len(sensors_agg)} agr√©gations ‚Üí {output_file}")

print("\n   üìã √âchantillon des donn√©es agr√©g√©es:")
print(sensors_agg.head())

# ============================================================================
# 2. CALCUL DES RENDEMENTS
# ============================================================================
print("\nüìä TRANSFORMATION 2: Calcul des rendements")
print("-" * 70)

# Charger les donn√©es
with open(RAW_PATH / "crops.json", 'r') as f:
    crops_data = json.load(f)
with open(RAW_PATH / "harvests.json", 'r') as f:
    harvests_data = json.load(f)
with open(RAW_PATH / "fields.json", 'r') as f:
    fields_data = json.load(f)

crops_df = pd.DataFrame(crops_data)
harvests_df = pd.DataFrame(harvests_data)
fields_df = pd.DataFrame(fields_data)

print(f"   ‚úÖ Charg√© {len(crops_df)} cultures")
print(f"   ‚úÖ Charg√© {len(harvests_df)} r√©coltes")

# Joindre les donn√©es
yield_df = harvests_df.merge(crops_df, on='crop_id') \
                      .merge(fields_df, on='field_id')

# Calculer les rendements
yield_df['actual_yield_t_ha'] = yield_df['quantity_tonnes'] / yield_df['area_ha']
yield_df['yield_variance_percent'] = ((yield_df['actual_yield_t_ha'] - yield_df['estimated_yield_t_ha']) / 
                                       yield_df['estimated_yield_t_ha'] * 100)

# Agr√©gation par type de culture
yield_summary = yield_df.groupby(['crop_type', 'category', 'season']).agg({
    'harvest_id': 'count',
    'quantity_tonnes': 'sum',
    'area_ha': 'sum',
    'actual_yield_t_ha': ['mean', 'min', 'max'],
    'yield_variance_percent': 'mean'
}).reset_index()

# Aplatir les colonnes
yield_summary.columns = ['crop_type', 'category', 'season', 'num_harvests', 
                         'total_production_tonnes', 'total_area_ha',
                         'avg_yield_t_ha', 'min_yield_t_ha', 'max_yield_t_ha', 
                         'avg_variance_percent']

# Trier par production
yield_summary = yield_summary.sort_values('total_production_tonnes', ascending=False)

# Sauvegarder
output_file = PROCESSED_PATH / "yield_analysis.json"
yield_summary.to_json(output_file, orient='records', indent=2)
print(f"   ‚úÖ Sauvegard√© l'analyse des rendements ‚Üí {output_file}")

print("\n   üìã Rendements par culture:")
print(yield_summary.head(10))

# ============================================================================
# 3. D√âTECTION D'ANOMALIES
# ============================================================================
print("\nüìä TRANSFORMATION 3: D√©tection d'anomalies")
print("-" * 70)

# Anomalies dans les capteurs (z-score > 3)
sensor_stats = sensors_df.groupby('sensor_type')['value'].agg(['mean', 'std']).reset_index()
sensors_with_stats = sensors_df.merge(sensor_stats, on='sensor_type')
sensors_with_stats['z_score'] = (sensors_with_stats['value'] - sensors_with_stats['mean']) / sensors_with_stats['std']

anomalies_sensors = sensors_with_stats[abs(sensors_with_stats['z_score']) > 3][
    ['sensor_id', 'field_id', 'sensor_type', 'timestamp', 'value', 'unit', 'z_score']
].sort_values('z_score', ascending=False)

print(f"   ‚ö†Ô∏è  D√©tect√© {len(anomalies_sensors)} anomalies dans les capteurs")

# Anomalies dans les rendements (< 50% de la moyenne)
avg_yields = yield_df.groupby('crop_type')['actual_yield_t_ha'].mean().reset_index()
avg_yields.columns = ['crop_type', 'avg_yield']

yield_with_avg = yield_df.merge(avg_yields, on='crop_type')
anomalies_yield = yield_with_avg[yield_with_avg['actual_yield_t_ha'] < yield_with_avg['avg_yield'] * 0.5][
    ['crop_id', 'field_id', 'crop_type', 'actual_yield_t_ha', 'avg_yield']
].copy()
anomalies_yield['deviation_percent'] = ((anomalies_yield['actual_yield_t_ha'] / anomalies_yield['avg_yield'] - 1) * 100)
anomalies_yield = anomalies_yield.sort_values('deviation_percent')

print(f"   ‚ö†Ô∏è  D√©tect√© {len(anomalies_yield)} rendements anormalement bas")

# Sauvegarder
output_file = PROCESSED_PATH / "anomalies_sensors.json"
anomalies_sensors.to_json(output_file, orient='records', date_format='iso', indent=2)
print(f"   ‚úÖ Sauvegard√© anomalies capteurs ‚Üí {output_file}")

output_file = PROCESSED_PATH / "anomalies_yield.json"
anomalies_yield.to_json(output_file, orient='records', indent=2)
print(f"   ‚úÖ Sauvegard√© anomalies rendements ‚Üí {output_file}")

if len(anomalies_sensors) > 0:
    print("\n   üìã Exemples d'anomalies capteurs:")
    print(anomalies_sensors.head())

if len(anomalies_yield) > 0:
    print("\n   üìã Exemples d'anomalies rendements:")
    print(anomalies_yield.head())

# ============================================================================
# 4. RAPPORT SYNTH√âTIQUE
# ============================================================================
print("\nüìä TRANSFORMATION 4: Rapport synth√©tique")
print("-" * 70)

# Charger les donn√©es manquantes
with open(RAW_PATH / "farms.json", 'r') as f:
    farms_data = json.load(f)
with open(RAW_PATH / "sales.json", 'r') as f:
    sales_data = json.load(f)

farms_df = pd.DataFrame(farms_data)
sales_df = pd.DataFrame(sales_data)

# Statistiques globales
report = {
    "generated_at": datetime.now().isoformat(),
    "summary": {
        "total_farms": int(len(farms_df)),
        "total_area_ha": float(farms_df['total_area_ha'].sum()),
        "total_production_tonnes": float(harvests_df['quantity_tonnes'].sum()),
        "total_revenue_fcfa": float(sales_df['total_amount'].sum()),
        "avg_yield_t_ha": float(yield_df['actual_yield_t_ha'].mean())
    },
    "top_crops": yield_summary.head(5).to_dict('records'),
    "anomalies": {
        "sensor_anomalies": int(len(anomalies_sensors)),
        "yield_anomalies": int(len(anomalies_yield))
    },
    "by_category": yield_summary.groupby('category').agg({
        'total_production_tonnes': 'sum',
        'avg_yield_t_ha': 'mean'
    }).to_dict('index')
}

# Sauvegarder
report_path = PROCESSED_PATH / "summary_report.json"
with open(report_path, 'w', encoding='utf-8') as f:
    json.dump(report, f, indent=2, ensure_ascii=False)

print(f"   ‚úÖ Rapport synth√©tique g√©n√©r√© ‚Üí {report_path}")

# ============================================================================
# R√âSUM√â
# ============================================================================
print("\n" + "=" * 70)
print("‚úÖ TRANSFORMATIONS TERMIN√âES")
print("=" * 70)
print("\nüìä R√©sum√© des transformations:")
print(f"   1. Capteurs agr√©g√©s: {len(sensors_agg)} enregistrements")
print(f"   2. Analyse rendements: {len(yield_summary)} cultures")
print(f"   3. Anomalies capteurs: {len(anomalies_sensors)}")
print(f"   4. Anomalies rendements: {len(anomalies_yield)}")
print(f"\nüíæ Donn√©es sauvegard√©es dans: {PROCESSED_PATH}/")
print(f"‚è∞ Heure de fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 70)
