# ğŸ“š Documentation DataEnginerFlow360

## Table des MatiÃ¨res

- [Architecture](#architecture)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Monitoring](#monitoring)
- [Troubleshooting](#troubleshooting)

## Architecture

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGESTION LAYER                          â”‚
â”‚  â€¢ Kafka Streaming                                          â”‚
â”‚  â€¢ API Batch (REST)                                         â”‚
â”‚  â€¢ File Batch (CSV, JSON, Parquet)                         â”‚
â”‚  â€¢ Fake Data Generation (Faker)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROCESSING LAYER                          â”‚
â”‚  â€¢ PySpark Structured Streaming (Real-time)                â”‚
â”‚  â€¢ PySpark Batch (Complex transformations)                 â”‚
â”‚  â€¢ dbt (Data Warehouse - Star Schema)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ORCHESTRATION (Airflow)                    â”‚
â”‚  â€¢ batch_ingestion_dag (2:00 AM)                           â”‚
â”‚  â€¢ pyspark_transformation_dag (3:00 AM)                    â”‚
â”‚  â€¢ dbt_dag (4:00 AM)                                       â”‚
â”‚  â€¢ master_pipeline_dag (Orchestration)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MONITORING (Prometheus + Grafana)              â”‚
â”‚  â€¢ Prometheus (Metrics collection)                         â”‚
â”‚  â€¢ Grafana (Visualization)                                 â”‚
â”‚  â€¢ Exporters (PostgreSQL, Kafka, Airflow, Docker)         â”‚
â”‚  â€¢ Custom Metrics (Data Quality)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Installation

### PrÃ©requis

- Docker & Docker Compose
- Python 3.12+
- Java 11 (pour PySpark)
- Git

### Ã‰tapes d'Installation

1. **Cloner le repository**

```bash
git clone https://github.com/kalpafall/DataEnginerFlow360.git
cd DataEnginerFlow360
```

2. **CrÃ©er l'environnement virtuel**

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. **Installer les dÃ©pendances**

```bash
pip install -r requirements.txt
```

4. **Configurer Java (pour PySpark)**

```bash
# Ubuntu/Debian
sudo apt install openjdk-11-jdk
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```

5. **DÃ©marrer les services Docker**

```bash
cd docker
docker-compose up -d
```

## Configuration

### PostgreSQL

Fichier: `transformation/dbt/profiles.yml`

```yaml
dataflow360:
  target: dev
  outputs:
    dev:
      type: postgres
      host: localhost
      user: postgres
      password: 1234 # Changez ceci
      port: 5432
      dbname: dataenginerflow360
```

### Prometheus

Fichier: `docker/prometheus/prometheus.yml`

- Scrape interval: 15s
- Targets: postgres-exporter, statsd-exporter, kafka-exporter, cadvisor

### Airflow

- Webserver: http://localhost:8080
- Credentials: admin/admin

## Utilisation

### Test Rapide du Pipeline

```bash
python3 test_pipeline.py
```

### ExÃ©cuter dbt

```bash
cd transformation/dbt
dbt run
dbt test
```

### ExÃ©cuter PySpark

```bash
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
python3 transformation/spark_transformation.py \
    --dataset transactions_fake \
    --type transactions \
    --aggregate
```

### DÃ©marrer Airflow

```bash
cd docker
docker-compose up -d airflow-webserver airflow-scheduler
```

## Monitoring

### AccÃ¨s aux Interfaces

| Service    | URL                   | Credentials |
| ---------- | --------------------- | ----------- |
| Grafana    | http://localhost:3000 | admin/admin |
| Prometheus | http://localhost:9090 | -           |
| Airflow    | http://localhost:8080 | admin/admin |
| cAdvisor   | http://localhost:8082 | -           |

### MÃ©triques Disponibles

#### Airflow

- `airflow_dag_run_duration_seconds` - DurÃ©e des DAGs
- `airflow_dag_run_success_total` - SuccÃ¨s des DAGs
- `airflow_dag_run_failed_total` - Ã‰checs des DAGs

#### PostgreSQL

- `pg_stat_database_numbackends` - Connexions actives
- `pg_stat_database_xact_commit` - Transactions committÃ©es

#### Kafka

- `kafka_consumergroup_lag` - Consumer lag
- `kafka_topic_partition_current_offset` - Offset actuel

#### Docker

- `container_cpu_usage_seconds_total` - CPU usage
- `container_memory_usage_bytes` - MÃ©moire utilisÃ©e

## Troubleshooting

### PostgreSQL: Port 5432 dÃ©jÃ  utilisÃ©

```bash
# ArrÃªter PostgreSQL local
sudo systemctl stop postgresql

# Ou utiliser un autre port dans docker-compose.yml
ports:
  - "5433:5432"
```

### Java not found (PySpark)

```bash
# Installer Java 11
sudo apt install openjdk-11-jdk

# DÃ©finir JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```

### dbt: Connection failed

```bash
# VÃ©rifier PostgreSQL
sudo -u postgres psql -d dataenginerflow360

# VÃ©rifier le mot de passe dans profiles.yml
```

### Docker: Permission denied

```bash
# Ajouter l'utilisateur au groupe docker
sudo usermod -aG docker $USER
newgrp docker
```

## Structure des DonnÃ©es

### Data Lake

```
data_lake/
â”œâ”€â”€ raw/           # DonnÃ©es brutes
â”œâ”€â”€ processed/     # DonnÃ©es transformÃ©es (PySpark)
â””â”€â”€ curated/       # DonnÃ©es finales (PostgreSQL)
```

### Star Schema (dbt)

- **Dimensions**: dim_users
- **Facts**: fact_transactions

## Performance

### Optimisations RecommandÃ©es

1. **PySpark**: Ajuster `spark.executor.memory`
2. **PostgreSQL**: CrÃ©er des index sur les colonnes frÃ©quemment requÃªtÃ©es
3. **Kafka**: Augmenter `num.partitions` pour le parallÃ©lisme
4. **Airflow**: Ajuster `parallelism` et `dag_concurrency`

## SÃ©curitÃ©

### Bonnes Pratiques

- âœ… Changer les mots de passe par dÃ©faut
- âœ… Utiliser des secrets pour les credentials
- âœ… Activer SSL pour les connexions
- âœ… Limiter l'accÃ¨s rÃ©seau avec des firewalls
- âœ… Sauvegarder rÃ©guliÃ¨rement les donnÃ©es

## Support

- **Issues**: https://github.com/kalpafall/DataEnginerFlow360/issues
- **Email**: fallyama2003@gmail.com

## Licence

MIT License - voir [LICENSE](../LICENSE)
